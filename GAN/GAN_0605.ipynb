{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"XPVNF96s2l97","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717693059416,"user_tz":-540,"elapsed":8160,"user":{"displayName":"송석현","userId":"12766017966361977290"}},"outputId":"64ca1a51-df05-49eb-ad33-26bc80472953"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From <ipython-input-1-361c7e3c318b>:11: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.config.list_physical_devices('GPU')` instead.\n"]},{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","GPU Available:  True\n","Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.keras.layers import Layer, Input, Conv2D, Conv2DTranspose, Flatten, Dense, LeakyReLU, BatchNormalization, ReLU, Activation, Reshape, ZeroPadding2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","print(\"GPU Available: \", tf.test.is_gpu_available())\n","print(\"Devices:\", tf.config.list_physical_devices())\n","\n"]},{"cell_type":"code","source":["import os\n","import shutil\n","from tqdm import tqdm\n","import signal\n","from contextlib import contextmanager\n","import time\n","\n","# Setting up a timeout handler using signals\n","class TimeoutException(Exception):\n","    pass\n","\n","@contextmanager\n","def time_limit(seconds):\n","    def signal_handler(signum, frame):\n","        raise TimeoutException(\"Timed out!\")\n","    signal.signal(signal.SIGALRM, signal_handler)\n","    signal.alarm(seconds)\n","    try:\n","        yield\n","    finally:\n","        signal.alarm(0)\n","\n","# Function to copy a file with a timeout\n","def copy_file_with_timeout(src, dst, timeout=10):\n","    try:\n","        with time_limit(timeout):\n","            shutil.copy(src, dst)\n","        return True\n","    except TimeoutException as e:\n","        print(f\"Timeout occurred for {os.path.basename(src)}: {e}\")\n","        return False\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Set the source and destination paths\n","source_path = '/content/drive/My Drive/GANProject/spec_512'\n","destination_path = '/content/GANProject/spec512'\n","\n","# Ensure the destination directory exists\n","os.makedirs(destination_path, exist_ok=True)\n","\n","# List all npy files and copy them with a timeout and retry if needed\n","files = [f for f in os.listdir(source_path) if f.endswith('.npy')]\n","for file in tqdm(files, desc=\"Copying files\"):\n","    src_file = os.path.join(source_path, file)\n","    dest_file = os.path.join(destination_path, file)\n","    if not os.path.exists(dest_file):  # 이미 파일이 존재하지 않는 경우에만 복사\n","      success = copy_file_with_timeout(src_file, dest_file, timeout=30)  # Set timeout to 30 seconds\n","      if not success:\n","          drive.mount('/content/drive', force_remount= True)\n","          print(f\"Retrying {file}...\")\n","          time.sleep(5)  # Wait for 5 seconds before retrying\n","          copy_file_with_timeout(src_file, dest_file, timeout=30)  # Corrected function call for retry\n","\n","print(\"Copy complete\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m1T3npVPsnJy","outputId":"451c29d0-016b-4c0c-fb51-5332628802e2","executionInfo":{"status":"ok","timestamp":1717650719137,"user_tz":-540,"elapsed":1103920,"user":{"displayName":"송석현","userId":"12766017966361977290"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["Copying files: 100%|██████████| 21172/21172 [18:03<00:00, 19.54it/s]"]},{"output_type":"stream","name":"stdout","text":["Copy complete\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SMZ4ONnwOpOq"},"outputs":[],"source":["def load_spectrogram(file_path):\n","    # EagerTensor에서 바로 numpy 배열로 변환 후 decode\n","    file_path = file_path.numpy().decode()\n","    spec = np.load(file_path)\n","    spec = np.expand_dims(spec, axis=-1)  # 채널 차원 추가\n","    factor = np.max(spec) - np.min(spec)\n","    if factor > 0:\n","        spec = 2 * (spec - np.min(spec)) / factor - 1  # -1과 1 사이로 정규화\n","    return spec\n","\n","def preprocess(file_path):\n","    # TensorFlow ops에서 사용할 수 있도록 load_spectrogram을 wrapper 함수로 호출\n","    spectrogram = tf.py_function(load_spectrogram, [file_path], Tout=[tf.float32])\n","    spectrogram = spectrogram[0]\n","    return spectrogram\n","\n","def create_dataset(data_dir, batch_size=32):\n","    # 파일 경로 로드\n","    file_paths = [os.path.join(data_dir, fname) for fname in os.listdir(data_dir) if fname.endswith('.npy')]\n","    print(\"file_paths\")\n","    # TensorFlow Dataset 객체 생성\n","    dataset = tf.data.Dataset.from_tensor_slices(file_paths)\n","    print(\"tensor_slice\")\n","    # 파일 경로를 실제 데이터로 변환\n","    dataset = dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n","    print(\"dataset.map\")\n","    # 배치 처리 및 prefetching\n","    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","    print(\"dataset.batch\")\n","    # 데이터셋의 배치 형태를 확인하기 위한 코드\n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rJ4hjQO0KJx0"},"outputs":[],"source":["def build_generator(noise_shape):\n","    #input size: 1024\n","    inputs = Input(shape=noise_shape)\n","\n","    x = Dense(32*32*32)(inputs)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = Reshape((32, 32, 32))(x)\n","    # Upsampling\n","    x = Conv2DTranspose(256, kernel_size=4, strides=2, padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    #64*64*256\n","    x = Conv2DTranspose(128, kernel_size=4, strides=2, padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    #128*128*128\n","    x = Conv2DTranspose(64, kernel_size=4, strides=2, padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    #256*256*64\n","    x = Conv2DTranspose(1, kernel_size=4, strides=2, padding='same')(x)\n","    #512*512*1\n","    x = Activation('tanh')(x)\n","\n","    return Model(inputs, x)\n","\n","def build_discriminator(input_shape):\n","    #input size: 512*512\n","    inputs = Input(shape=input_shape)\n","\n","    x = Conv2D(1, kernel_size=5, strides=2, padding='same')(inputs)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    x = RandomShuffleLayer()(x)\n","\n","    #256*256*64\n","    x = Conv2D(16, kernel_size=5, strides=2, padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    x = RandomShuffleLayer()(x)\n","    '''\n","    #128*128*128\n","    x = Conv2D(256, kernel_size=5, strides=2, padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    x = RandomShuffleLayer()(x)\n","    '''\n","    x= Flatten()(x)\n","    x= Dense(64)(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    #64*64*256\n","    x = Dense(1)(x)\n","    x = Activation('sigmoid')(x)\n","\n","    return Model(inputs, x)\n","\n","\n","class RandomShuffleLayer(tf.keras.layers.Layer):\n","    def __init__(self, **kwargs):\n","        super(RandomShuffleLayer, self).__init__(**kwargs)\n","\n","    def call(self, inputs):\n","        # Assuming inputs are of shape [batch_size, height, width, channels]\n","        def shuffle_along_axis(image):\n","            # Shuffle along the width (axis=1)\n","            shuffled = tf.random.shuffle(tf.transpose(image, [1, 0, 2]))\n","            return tf.transpose(shuffled, [1, 0, 2])\n","\n","        # Apply to each image in the batch\n","        outputs = tf.map_fn(shuffle_along_axis, inputs, dtype=tf.float32)\n","        return outputs\n"]},{"cell_type":"code","source":["generator = build_generator((100,))\n","\n","noise = tf.random.normal([1, 100])\n","generated_image = generator(noise, training=False)\n","\n","plt.imshow(generated_image[0, :, :, 0], cmap='gray')"],"metadata":{"id":"nS_OyXep5jgo"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vBEsf1-ccuQN"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def save_spectrogram(spectrogram, epoch, output_dir, X_mean=-5, X_std=45):\n","    # Ensure the output directory exists\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    # Convert EagerTensor to numpy if not already\n","    if isinstance(spectrogram, tf.Tensor):\n","        spectrogram = spectrogram.numpy()\n","\n","    # Squeeze to remove single-dimensional entries from the shape\n","    spectrogram = spectrogram.squeeze()\n","\n","    # Reversing the normalization formula to get the original log magnitude\n","    X_mag = (spectrogram * X_std) + X_mean\n","    np.save(os.path.join(output_dir, f'spectrogram_epoch_{epoch}.npy'), X_mag)\n","\n","    # Configure the plot\n","    plt.figure(figsize=(10, 4))\n","    plt.imshow(X_mag, aspect='auto', origin='lower', cmap='viridis')\n","    plt.colorbar(format='%+2.0f dB')\n","    plt.title(f'Spectrogram at Epoch {epoch}')\n","    plt.xlabel('Time')\n","    plt.ylabel('Frequency')\n","    plt.tight_layout()\n","\n","    # Save the figure\n","    plt.savefig(os.path.join(output_dir, f'spectrogram_epoch_{epoch}.png'))\n","    plt.close()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"75kSpTsGTLXR"},"outputs":[],"source":["np.set_printoptions(linewidth=200)\n","\n","@tf.function\n","\n","def train_step(images, valid, fake, generator, discriminator, combined, noise_shape):\n","    noise = tf.random.normal([tf.shape(images)[0]]+ noise_shape)\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","        generated_images = generator(noise, training=True)\n","        real_output = discriminator(images, training=True)\n","        fake_output = discriminator(generated_images, training=True)\n","\n","        # Calculate losses\n","        disc_loss_real = tf.keras.losses.binary_crossentropy(valid[:tf.shape(real_output)[0]], real_output, from_logits=False)\n","        disc_loss_fake = tf.keras.losses.binary_crossentropy(fake[:tf.shape(fake_output)[0]], fake_output, from_logits=False)\n","        disc_loss = (disc_loss_real + disc_loss_fake) / 2\n","\n","        # Calculate probabilities for real and fake\n","        real_prob = tf.math.reduce_mean(real_output)\n","        fake_prob = tf.math.reduce_mean(fake_output)\n","\n","        #tf.print(\"real_output: \", real_prob, summarize=-1)\n","        #tf.print(\"fake_output: \", fake_prob, summarize=-1)\n","\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n","    discriminator.optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n","\n","    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n","    generator.optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n","\n","\n","    #tf.print(\"gradients_of_discriminator: \", gradients_of_discriminator, summarize=-1)\n","    #tf.print(\"Discriminator weights: \", [var.name for var in discriminator.trainable_variables])\n","\n","    return disc_loss, gen_loss, real_prob, fake_prob\n","\n","import traceback\n","\n","def train_gan(generator, discriminator, combined, dataset, epochs, batch_size, noise_shape, save_interval, output_dir, start_epoch):\n","    noise_shape = list(noise_shape)\n","    print(\"train_gan started\")\n","    loss_log_path = os.path.join(output_dir, \"training_log.txt\")\n","        # Ensure the output directory exists\n","    os.makedirs(output_dir, exist_ok=True)\n","    valid = np.ones((batch_size, 1)) * 0.9 # Label Smoothing 적용\n","    fake = np.zeros((batch_size, 1))\n","\n","    with open(loss_log_path, \"w\") as file:\n","        file.write(\"Start of training\\n\")\n","\n","    try:\n","        for epoch in range(start_epoch, epochs):\n","            print(f\"Epoch {epoch+1} started\")\n","            for batch_index, data in enumerate(dataset):\n","                imgs = data[0] if isinstance(data, tuple) else data\n","                if tf.shape(imgs)[0] != batch_size:\n","                    continue  # Skip incomplete batches\n","                d_loss, g_loss, real_prob, fake_prob = train_step(imgs, valid, fake, generator, discriminator, combined, noise_shape)\n","                print(\".\", end=\"\")\n","                if (batch_index + 1) % 80 == 0:\n","                    print(\"\")\n","                    log_message = f\"Epoch {epoch + 1}, Batch {batch_index + 1}\\nD loss: {d_loss.numpy()}, \\nG loss: {g_loss.numpy()}\\nReal prob: {real_prob.numpy()*100:.2f}%, Fake prob: {fake_prob.numpy()*100:.2f}%\\n\"\n","                    print(log_message)\n","                    with open(loss_log_path, \"a\") as file:\n","                        file.write(log_message)\n","\n","\n","            if (epoch + 1) % save_interval == 0:\n","                generator.save(f'{output_dir}/generator_epoch_{epoch + 1}')\n","                discriminator.save(f'{output_dir}/discriminator_epoch_{epoch + 1}')\n","                noise = tf.random.normal([batch_size]+noise_shape)\n","                generated_spec= generator(noise, training=False)[0]\n","                save_spectrogram(generated_spec, epoch+1, output_dir)\n","\n","            with open(loss_log_path, \"a\") as file:\n","                file.write(f\"Epoch {epoch + 1} completed.\\n-------------------------------------------------\\n\")\n","\n","        with open(loss_log_path, \"a\") as file:\n","            file.write(\"End of training\\n\")\n","    except Exception as e:\n","        with open(loss_log_path, \"a\") as file:\n","            file.write(f\"Error occurred: {str(e)}\\n\")\n","            file.write(traceback.format_exc())"]},{"cell_type":"code","source":["# 모델을 불러와서 학습을 실행하는\n","\n","from tensorflow.keras.models import load_model\n","\n","\n","# 경로 설정\n","data_dir = '/content/GANProject/spec512'\n","output_dir = 'drive/MyDrive/GANProject/GAN_0606'\n","\n","# 저장된 모델 경로\n","generator_path = f'{output_dir}/generator_epoch_10'\n","discriminator_path = f'{output_dir}/discriminator_epoch_10'\n","# 하이퍼파라미터 설정\n","epochs = 200\n","batch_size = 8\n","save_interval = 5\n","\n","# 모델 불러오기\n","generator = load_model(generator_path)\n","discriminator = load_model(discriminator_path)\n","\n","noise_shape = (1024,)\n","input_shape = (512, 512, 1)\n","\n","# Discriminator의 훈련 가능 상태 설정\n","discriminator.trainable = True\n","\n","# Combined model 재구성\n","combined_input = Input(shape=noise_shape)\n","combined_output = discriminator(generator(combined_input))\n","combined = Model(combined_input, combined_output)\n","combined.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n","\n","# 데이터셋 다시 로드 (필요시)\n","dataset = create_dataset(data_dir, batch_size)\n","\n","\n","# 학습 재개\n","train_gan(generator, discriminator, combined, dataset, epochs, batch_size, noise_shape, save_interval=10, output_dir=output_dir, start_epoch=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":452},"id":"n_DL-4-xX89Z","executionInfo":{"status":"error","timestamp":1717694475381,"user_tz":-540,"elapsed":8260,"user":{"displayName":"송석현","userId":"12766017966361977290"}},"outputId":"a5781d77-7510-4892-8c8f-28498e8a2775"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["file_paths\n","tensor_slice\n","dataset.map\n","dataset.batch\n","train_gan started\n","Epoch 11 started\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-c8e820e7e8f5>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# 학습 재개\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-28-bf68b68ee37c>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(generator, discriminator, combined, dataset, epochs, batch_size, noise_shape, save_interval, output_dir, start_epoch)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# Skip incomplete batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m80\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0;31m# no_variable_creation function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m         return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    906\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":207},"id":"RCAqttsKO5Na","outputId":"df2e62fa-3ea4-438e-c5d5-b0f9e09c4025","executionInfo":{"status":"error","timestamp":1717746626754,"user_tz":-540,"elapsed":2,"user":{"displayName":"송석현","userId":"12766017966361977290"}}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'build_generator' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-92b029d62e93>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 모델 설정 및 컴파일\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'build_generator' is not defined"]}],"source":["# 경로 설정\n","data_dir = '/content/GANProject/spec512'\n","output_dir = 'drive/MyDrive/GANProject/GAN_0607'\n","\n","noise_shape = (1024,)\n","input_shape = (512, 512, 1)\n","\n","# 하이퍼파라미터 설정\n","epochs = 200\n","batch_size = 8\n","save_interval = 5\n","\n","# 모델 설정 및 컴파일\n","generator = build_generator(noise_shape)\n","generator.compile(loss='binary_crossentropy', optimizer=Adam(0.0005, 0.5))\n","discriminator = build_discriminator(input_shape)\n","discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0001, 0.5), metrics=['accuracy'])\n","\n","# Combined model 설정\n","discriminator.trainable = True\n","combined_input = Input(shape=noise_shape)\n","combined_output = discriminator(generator(combined_input))\n","combined = Model(inputs=combined_input, outputs=combined_output)\n","combined.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n","\n","\n","print(\"Generator model summary:\")\n","generator.summary()\n","print(\"Discriminator model summary:\")\n","discriminator.summary()\n","print(\"Discriminator weights: \", [var.name for var in discriminator.trainable_variables])\n","print(\"Combined model summary:\")\n","combined.summary()\n","\n","# 데이터셋 생성 및 훈련 시작\n","dataset = create_dataset(data_dir, batch_size)\n","\n","train_gan(generator, discriminator, combined, dataset, epochs, batch_size, noise_shape, save_interval, output_dir, start_epoch=0)\n","print(\"GAN Main ends\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[],"mount_file_id":"19IRCkmIQFUwBRThyOLJpLN8bQdtH89AY","authorship_tag":"ABX9TyMrHd/jiF4q9tmAtxMS90w2"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}